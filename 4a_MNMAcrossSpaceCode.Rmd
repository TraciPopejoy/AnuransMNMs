---
title: "HPC Code for Mechanistic Niche Models Across Space"
author: "TP DuBose"
date: "11/22/2022"
output: pdf_document
---

Below is the code I use to run many mechanistic niche models across the Southeastern United States region on the High Power Computer. I run it on the HPC to parallelize the code and save myself time. I run into an odd FORTRAN error and used the last answer on this [StackXchange question](https://stackoverflow.com/questions/7891073/time-out-an-r-command-via-something-like-try) to time out the process and prevent the core from hanging until the end of the SLURM job. 


```{r anuran parallel script, eval=F}
#interact -A usgs_rcs -t 2:00:00 -p normal_q -N 1 -c 2 # code to start an interactive session
#module load containers/singularity 
#singularity exec --bind=/fastscratch/tracidubose/AnuranMNMs /projects/arcsingularity/ood-rstudio141717-geospatial_4.1.1.sif Rscript pairedMCE_Rscript.r

# R script to programatically run Mechanistic Niche models ----
# by Traci DuBose, last edited 11/22/2022
# set up the libraries
.libPaths(.libPaths()[3:1])
#library(devtools)
#devtools::install_github('mrke/NicheMapR')
#devtools::install_github('ilyamaclean/microclima')
library(tidyverse); library(maps);  library(sf); library(parallel); library(hoardr); library(stars); library(NicheMapR)
# DATA INPUTS ------------
coress <- 10
 npts<- 10
# paths
PATH <- "./" #arc
PATH_out <- paste0(PATH, "results/") # where to save the output
# traits used to parameterize the ectotherm function
traits <- read.csv(paste0(PATH, "inputed_traits.csv")) %>%
  mutate(across(c('s.fossorial', 's.arboreal', 'nocturnal','diurnal','crepuscular'),
                as.numeric)) 
focal_spp<-traits %>% pull(species) %>% unique() # focal species to run models for
# completed points
pts_done <- read.csv('summarized_bodytemps.csv') %>% pull(rowid)
# points at which to run the microclimate model
pts_df<-read.csv(paste0(PATH, "points_to_run.csv")) %>%
          filter(!(rowid %in% pts_done),
                 grepl(', ', spp_all)) 
#npts<-nrow(pts_df)
# model parameters
start_date="01/01/2012"
end_date="31/12/2020"
cat('\ndata loaded\n')
# FUNCTION WHICH WE USE TO PARALLALIZE CODE ----------
# it should run the microclimate model and then an ectotherm model for each species found in that grid
anuranMNMs<-function(rw, write.micro.out=F){
  pt<-pts_df[pts_df$rowid==rw,]
  cat(paste0(rw, ' row number \n', round(pt[1,1],3), '  ',round(pt[1,2], 3),'\n'))
  ecto_out <- NULL
  ERR <- 1.5
  micro <- micro_ncep(loc = c(as.numeric(pt[1,1])-+0.00001,as.numeric(pt[1,2])+0.00001),
                     dstart = start_date, dfinish = end_date,
                     DEP = c(0, 2.5,  5,  10,  15,  20,  30,  50, 75,  100), #cm
                     minshade = 0, maxshade = 90, runshade=1,
                    # soilgrids=1,
                     spatial='./ncep_data/ncep_data',
                     dem.res=1000, # requested resolution DEM from elevatr in meters
                     Usrhyt = 0.01, # local height for organism
                     ERR = ERR, 
                     run.gads=2)
  gc()
  while(min(micro$metout[,1])==0 & ERR <= 6){
        cat("model crashed, trying a higher error tolerance \n")
        ERR <- ERR + 0.5
                # rerun the microclimate with slightly higher error tolerance allowed
        micro <- micro_ncep(loc = c(as.numeric(pt[1,1])-0.00001,as.numeric(pt[1,2])+0.00001),
                     dstart = start_date, dfinish = end_date,
                     DEP = c(0, 2.5,  5,  10,  15,  20,  30,  50, 75,  100), #cm
                     minshade = 0, maxshade = 90, runshade=1,
                    #soilgrids=1,
                     spatial='./ncep_data/ncep_data',
                     dem.res=1000, # requested resolution DEM from elevatr in meters
                     Usrhyt = 0.01, # local height for organism
                     ERR = ERR,
                     run.gads=2)
        gc()
cat(paste('row',rw,'tried error ', ERR, 'and it worked ==', min(micro$metout[,1])!=0, '\n'))
      }
if(min(micro$metout[,1])==0){
mc.df<-data.frame(rowid=rw,
           lat=micro$longlat[2],
           long=micro$longlat[1],
           notes='broken model',
           err=ERR) 
write.csv(mc.df, paste0(PATH_out, rw,'_microloc.csv'), row.names=F)
        }else{
mc.df<-data.frame(rowid=rw,
           lat=micro$longlat[2],
write.csv(mc.df, paste0(PATH_out, rw,'_microloc.csv'), row.names=F)
        }else{
mc.df<-data.frame(rowid=rw,
           lat=micro$longlat[2],
           long=micro$longlat[1],
           tRainfall=sum(micro$RAINFALL),
           aRainfall=sum(micro$RAINFALL)/(length(micro$dates2)/365),
           evel=micro$elev,
           slope=micro$SLOPE,
           aspect=micro$ASPECT,
           err=ERR) %>% 
mutate(across(-c(rowid, lat, long), ~round(.x, 3))) 
write.csv(mc.df, paste0(PATH_out, rw,'_microloc.csv'), row.names=F)
bind_cols(ppt=micro$RAINFALL, dat=micro$dates2) %>% mutate(year=substr(dat,1,4)) %>% 
        group_by(year) %>% 
        summarize(mppt=mean(ppt), sdppt=sd(ppt), tppt=sum(ppt), .groups='drop') %>%
left_join(micro$metout %>%
	     bind_cols(dat=micro$dates) %>%
	     mutate(year=substr(dat, 1,4)) %>% 
	     group_by(year) %>% summarize(across(c(TALOC, TAREF), list(mean=mean, sd=sd, min=min, max=max)), .groups='drop'),
	  by='year') %>%
mutate(across(-c(year), ~round(.x, 2)), rowid=rw) %>%
write.csv(paste0(PATH_out, rw, '_ppt_dat.csv'), row.names=F) 
gc()

# ECTOTHERM MODEL STARTS -------
  for(spp in focal_spp){
    if(grepl(spp, pt$spp_all)){
      spp_traits <- traits %>% filter(species == spp)
      cat(paste('ectotherm model for', spp, '\n'))
      ecto<-ectotherm(Ww_g=spp_traits["Mass"], 
                      shape = 4, # shape based on leopard frog
                      CT_max=spp_traits["CTmax"], 
                      CT_min=spp_traits["CTmin"], 
                      T_pref=spp_traits["Tpref"],
                      # when is activity allowed
                      diurn=spp_traits["diurnal"],
                      nocturn=spp_traits["nocturnal"],
                      crepus=spp_traits["crepuscular"],
                      # can it go into a burrow or climb to cool off
                      burrow=spp_traits["s.fossorial"],
                      climb=spp_traits["s.arboreal"],
                      shdburrow = 1, #the animal's retreat is in the open (0), in the shade when above or below CTmin in sun (1) or in shade always
                      maxdepth = 10, #maximum depth of the burrow
                      T_F_min=max(c(as.numeric(spp_traits["Tforage_min"]), as.numeric(spp_traits["Tmerge"]))),
                      T_F_max=min(c(as.numeric(spp_traits["Tforage_max"]), as.numeric(spp_traits["CTmax"]))),
                      T_RB_min=spp_traits["Tmerge"],
                      T_B_min=spp_traits["Tmerge"],
                      # microclimate port from parent environment
                      nyears= micro$nyears, 
                      minshades = micro$minshade, 
                      maxshades = micro$maxshade, 
                      alpha_sub = (1 - micro$REFL), 
                      DEP = micro$DEP, KS = micro$KS, b = micro$BB, 
                      PE = micro$PE, metout = micro$metout, shadmet = micro$shadmet, 
                      soil = micro$soil, shadsoil = micro$shadsoil, soilmoist = micro$soilmoist, 
                      shadmoist = micro$shadmoist, humid = micro$humid, shadhumid = micro$shadhumid, 
                      soilpot = micro$soilpot, shadpot = micro$shadpot, tcond = micro$tcond, 
                      shadtcond = micro$shadtcond, rainfall = micro$RAINFALL, 
                      preshr = rep(101325 * ((1 - 
                                                (0.0065 * as.numeric(micro$elev)/288))^(1/0.190284)), 
                                   nrow(micro$metout)), elev = as.numeric(micro$elev), 
                      longitude = as.numeric(micro$longlat[1]), 
                      latitude = as.numeric(micro$longlat[2]),
		      enberr=ifelse(spp == "Lithobates catesbeianus", .015, .055))
  
bodytemps<-ecto$environ %>% as_tibble() %>%
  mutate(WT=as.numeric(spp_traits["CTmax"])-TC) %>% 
  group_by(YEAR, DOY) %>% 
  summarize(activity0=sum(ACT == 0),
         activity1=sum(ACT == 1),
         activity2=sum(ACT == 2),
         shadeMean=round(mean(SHADE),2),
         across(c(WT,TC,TA,TSUB, TSKY, DEP), list(mean=mean, max=max, min=min)),
         nHoursAboveCTmax=sum(WT < 0),
	 species=spp,
	 rowid=rw, .groups='drop') %>%
	 mutate(across(c(ends_with('mean'), ends_with('min'), ends_with('max')), ~round(.x, 3))) %>%
  group_by(species, rowid) %>%
  summarize(nDays=sum(nHoursAboveCTmax != 0),
  	meannH=mean(nHoursAboveCTmax), 
  	WT_ptmin=min(WT_min),
  	WT_min25=quantile(WT_min, .25),
  	WT_25=quantile(WT_mean, .25),
  	WT_75=quantile(WT_mean, .75),
  	WT_ptmean=mean(WT_mean),
  	nhrF=sum(activity2), .groups='drop')
ecto_out<-bind_rows(ecto_out, bodytemps)
gc()
}
}
write.csv(ecto_out, paste0(PATH_out, rw, "_bodytemps_sum.csv"), row.names=F)
}
return(ecto_out)
}

eval_fork <- function(row, timeout=720){

  #this limit must always be higher than the timeout on the fork!
  setTimeLimit(timeout+5);      
  starttime <- Sys.time()

  #dispatch based on method
  ##NOTE!!!!! Due to a bug in mcparallel, we cannot use silent=TRUE for now.
  myfork<-parallel::mcparallel(anuranMNMs(row))

  #wait max n seconds for a result.
  myresult <- parallel::mccollect(myfork, wait=FALSE, timeout=timeout)
  
  enddtime <-  Sys.time()
  totaltime <- as.numeric(enddtime - starttime, units='secs')  
  #try to avoid bug/race condition where mccollect returns null without waiting full timeout.
  #see https://github.com/jeroenooms/opencpu/issues/131
  #waits for max another 2 seconds if proc looks dead 
  while(is.null(myresult) && totaltime < timeout && totaltime < 2) {
     Sys.sleep(.1)
     enddtime <- Sys.time();
     totaltime <- as.numeric(enddtime - starttime, units="secs")
     myresult <- parallel::mccollect(myfork, wait = FALSE, timeout = timeout);
  }

  #kill fork after collect has returned
  tools::pskill(myfork$pid, tools::SIGKILL);    
  tools::pskill(-1 * myfork$pid, tools::SIGKILL);  

  #clean up:
  parallel::mccollect(myfork, wait=FALSE);

  #timeout?
  if(is.null(myresult)){
    stop("R call did not return within ", timeout, " seconds. Terminating process.", call.=FALSE);      
  }

  #move this to distinguish between timeout and NULL returns
  myresult <- myresult[[1]];

  #reset timer
  setTimeLimit();     

  #forks don't throw errors themselves
  if(inherits(myresult,"try-error")){
    #stop(myresult, call.=FALSE);
    stop(attr(myresult, "condition"));
  }

  #send the buffered response
  return(myresult);  
  
}


mclapply(pts_df$rowid[1:npts],
		  eval_fork,
		  mc.cores=coress)
```

I automate this code with the following SLURM job submission script. To speed things up, I 

```{r slurm script, eval=F}
#!/bin/bash
#SBATCH -N 1
#SBATCH --ntasks=75
#SBATCH --mem-per-cpu=1900
#SBATCH -t 55;00:00
#SBATCH -J avoid_mem_error
#SBATCH -p normal_q
#SBATCH --account=
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=

# info: -N=nodes
#ntasks=cores
#mem-per-cpu=memory requested (note, it's multiplied by ntasks, so if you ask for 2 cores, and 80 mem-per-cpu, you'll get 160 G)
#-t = time requested
#-J = job name
#-p = partitiion
#you don't need to mail requests if you don't want to get notifications about the job running, you could just delete

cd /fastscratch/tracidubose/AnuranMNMs #project folder

# make sure the correct files are used
#cp /home/tracidubose/AnuranMNMs/inputed_physio_traits_11152022.csv inputed_traits.csv
#cp /home/tracidubose/AnuranMNMs/points_ran_2022-11-17.csv points_to_run.csv

module load containers/singularity # this line is necessary
echo "Modules loaded:" #these lines are just extra until L34
module list

echo " "
echo "============================="
echo "Running from:"
pwd
echo " "
echo "============================="


echo "Running predictor setup step..."
echo "============================="
singularity exec --bind=/fastscratch/tracidubose/AnuranMNMs /projects/arcsingularity/ood-rstudio141717-geospatial_4.1.1.sif Rscript pairedMCE_Rscript.r
echo "============================="
echo " "
```

And then I use the code below to collate and summarize all the completed models. 

```{r building body temps, eval=F}
# set up the libraries
.libPaths(.libPaths()[3:1])
library(tidyverse)

micro_out<-NULL
for(i in list.files('results/', pattern='microloc', full.names = T)){
  micro_out<-bind_rows(micro_out,
                      read.csv(i))
}
write.csv(micro_out, 'microclimate_info.csv', row.names=F)

clim_out<-NULL
for(i in list.files('results/', pattern='ppt_dat', full.names=T)){
  clim_out<-bind_rows(clim_out,
		      read.csv(i))
}
write.csv(clim_out, 'climate_data.csv', row.names=F)

ecto_out<-NULL
for(i in list.files('results', pattern='bodytemps_sum.csv', full.names = T)){
  ecto_out<-bind_rows(ecto_out,
                      read.csv(i))
}

write.csv(ecto_out, 'summarized_bodytemps.csv', row.names=F)

cat(paste('missing bt', micro_out$rowid[!(micro_out$rowid %in% unique(ecto_out$rowid))], '\n'))
write.table(paste0('results/', micro_out$rowid[!(micro_out$rowid %in% unique(ecto_out$rowid))],'_microloc.csv'), 'missingbt.txt', sep="/t", quote=F, row.names=F)
cat(paste('missing micro', ecto_out$rowid[!(ecto_out$rowid %in% unique(micro_out$rowid))], '\n'))

# Outputs  in a raster ---------------
library(sf); library(maps);library(stars)
# study extent
se<-st_as_sf(map('state',c('mississippi', 'georgia', 'florida', 'south carolina',
                           'north carolina', 'virginia', 'alabama', 'tennessee'),
                 fill=T, plot=F)) %>%
  st_make_valid() %>%
  st_transform(st_crs("+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=km +no_defs"))
# create raster of study extent
se_r<-st_rasterize(se, dx=1, dy=1) %>% #turn into a raster of 1x1 kilometers
  st_as_sf(as_points = FALSE, merge = FALSE) %>%  #turn into a polygon
  rowid_to_column() # add an id column

focal_spp <- unique(ecto_out$species)
# convert the ecto_out to a wide dataframe so that each attribute is the result of a single species
ecto_wt<-ecto_out %>% select(rowid, species, WT_ptmin) %>%
  pivot_wider(names_from=species, values_from=WT_ptmin)
#ecto_25<-ecto_out %>% select(rowid, species, WT_min25) %>%
#          pivot_wider(names_from=species, values_from=WT_min25)

# join the spatial polygon with the ectotherm output
ecto_se<-se_r %>% right_join(ecto_wt, by='rowid') %>%
  left_join(ecto_out %>% group_by(rowid) %>%
              summarize(n_spp=n(),
                        mean_WTmin=round(mean(WT_ptmin),4),
                        sd_WTmin=round(sd(WT_ptmin),4),
                        mean_WT25=round(mean(WT_min25),4),
                        sd_WT25=round(sd(WT_min25),4)),
            by='rowid')
all_res<-NULL
for(spp in focal_spp){
  tettt <- ecto_se %>% select(rowid, ID, all_of(spp)) %>%
    rename(value=all_of(spp)) %>%
    filter(!is.na(value)) 
  resul <- tettt %>% as_tibble() %>%
    summarize(species=spp,
              mean_WTmin=mean(value),
              below0=sum(value < 0),
              below2=sum(value < 2),
              n=n()) %>%
    bind_cols(area=tettt %>% st_union() %>% st_area(.))
  all_res<- bind_rows(all_res, resul)
}
all_res
write.csv(all_res, 'anuranMNMsensitivity.csv')

ecto_rast <- ecto_se %>% st_rasterize()

# export as rds
saveRDS(ecto_rast, "WT_stars.rds")

# plot most abundant species
pdf("q_WT.pdf")

# Creating a plot
plot(ecto_rast[15], breaks='equal')

# Closing the graphical device
dev.off()
```

Below code is for error checking:

```{r}
micro_out <- read.csv('intermediate_results/microclimate_info_221216.csv')
micro_out %>%
  ggplot()+geom_histogram(aes(x=err), binwidth = .5)+
  scale_x_continuous('Microclimate Error Tolerance', label=seq(1.5:6))
```
